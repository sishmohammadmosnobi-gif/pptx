{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSbk/6m1ita/wWpKmWVfbF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sishmohammadmosnobi-gif/pptx/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnqQXJzGiaYj"
      },
      "outputs": [],
      "source": [
        "# ====== 1) Install required packages (run once) ======\n",
        "!pip install -q tensorflow tensorflow-datasets seaborn scikit-learn matplotlib opencv-python\n",
        "\n",
        "# ====== 2) Imports & config ======\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# reproducibility (not guaranteed across GPUs)\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check GPU\n",
        "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "# ====== 3) Hyperparameters ======\n",
        "IMG_SIZE = 128        # try 96 if you get OOM\n",
        "BATCH_SIZE = 32       # reduce to 16 if OOM\n",
        "EPOCHS = 2\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "CLASS_NAMES = ['cat', 'dog']\n",
        "\n",
        "# ====== 4) Load dataset (tfds) and split ======\n",
        "# cats_vs_dogs is downloaded automatically by tfds if missing\n",
        "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "print(\"Dataset loaded. Num classes:\", ds_info.features['label'].num_classes)\n",
        "\n",
        "# ====== 5) Preprocessing function ======\n",
        "def preprocess(image, label):\n",
        "    # convert to float32 in [0,1] and resize\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "# ====== 6) Build performant input pipelines ======\n",
        "train_ds = (ds_train\n",
        "            .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "            .shuffle(2000)\n",
        "            .batch(BATCH_SIZE)\n",
        "            .cache()\n",
        "            .prefetch(AUTOTUNE))\n",
        "\n",
        "val_ds = (ds_val\n",
        "          .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "          .batch(BATCH_SIZE)\n",
        "          .cache()\n",
        "          .prefetch(AUTOTUNE))\n",
        "\n",
        "test_ds = (ds_test\n",
        "           .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "           .batch(BATCH_SIZE)\n",
        "           .prefetch(AUTOTUNE))\n",
        "\n",
        "# ====== 7) Data augmentation layer (used inside model) ======\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.08),\n",
        "    layers.RandomZoom(0.08),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "# ====== 8) Build model (explicit Input) ======\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),   # explicit input\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(2, activation='softmax')   # 2 classes\n",
        "], name=\"cats_dogs_cnn\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ====== 9) Compile model ======\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ====== 10) Callbacks ======\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "# ====== 11) Train ======\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ====== 12) Plot training curves ======\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ====== 13) Evaluate with classification report & confusion matrix ======\n",
        "# Predict on the whole test set (fast)\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Get predictions batch-wise\n",
        "preds = model.predict(test_ds)              # shape (N,2)\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "# Collect true labels from test_ds (preserving order used by predict)\n",
        "for _, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(pred_labels[:len(y_true)])  # ensure same length\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ====== 14) Visualize some test predictions ======\n",
        "import random\n",
        "plt.figure(figsize=(12,8))\n",
        "rows = 3\n",
        "cols = 4\n",
        "count = 0\n",
        "for images, labels in test_ds.take(3):  # take a few batches\n",
        "    for i in range(min(images.shape[0], cols)):\n",
        "        if count >= rows*cols:\n",
        "            break\n",
        "        img = images[i].numpy()\n",
        "        true_label = CLASS_NAMES[int(labels[i].numpy())]\n",
        "        pred = model.predict(img[np.newaxis,...])  # shape (1,2)\n",
        "        pred_label = CLASS_NAMES[int(np.argmax(pred, axis=1)[0])]\n",
        "        plt.subplot(rows, cols, count+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"T:{true_label} | P:{pred_label}\")\n",
        "        plt.axis('off')\n",
        "        count += 1\n",
        "    if count >= rows*cols:\n",
        "        break\n",
        "plt.show()\n"
      ]
    }
  ]
}